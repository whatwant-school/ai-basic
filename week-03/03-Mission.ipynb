{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRkQAdSZn-m"
      },
      "source": [
        "## Q1. 본격적으로 Numpy와 친해지기 위해서 다양한 연산을 연습해볼 예정입니다. 무작위의 데이터를 가진 5x3의 행렬을 가지는 numpy array와 3x2 행렬을 가지는 numpy array를 만든 후 행열곱 연산을 진행해보세요. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J343ITmOZlsv",
        "outputId": "a79c039a-2638-4926-917d-1195128459c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.77418473  2.26402199]\n",
            " [-0.66435358  1.68155867]\n",
            " [-0.55493901  1.48303461]\n",
            " [-0.73642662  1.65564192]\n",
            " [-0.9854907   2.1366853 ]] (5, 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "arr1 = np.random.uniform(0, 1, 15).reshape(5, 3)  # 균등 분포\n",
        "arr2 = np.random.normal(0, 1, 6).reshape(3, 2)    # 정규 분포\n",
        "\n",
        "dot = arr1.dot(arr2)\n",
        "\n",
        "print(dot, dot.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3AMgJpNfKOL"
      },
      "source": [
        "## Q2. 두번째로는 numpy에서 자주 사용하는 concatenate 연산에 대한 미션을 수행해보겠습니다. 이제 Numpy에서 사용하는 2개의 numpy array가 있을때, 두 numpy array의 concatenate 연산을 구해보세요.  \n",
        "\n",
        "- axis는 0, 1 두개로 연산한 결과를 출력해보세요.\n",
        "- 각 데이터가 어떤 형태로 더해지는지 확인해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz0TnTLEfXHM",
        "outputId": "9f3ce36b-615d-4c81-f6cd-505596c71666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 5.  7.]\n",
            " [ 9. 11.]\n",
            " [ 2.  4.]\n",
            " [ 6.  8.]]\n",
            "[[ 5.  7.  2.  4.]\n",
            " [ 9. 11.  6.  8.]]\n"
          ]
        }
      ],
      "source": [
        "arr1 = np.array([[5, 7], [9, 11]], float)\n",
        "arr2 = np.array([[2, 4], [6, 8]], float)\n",
        "\n",
        "concat_1 = np.concatenate((arr1, arr2), axis=0)  # row 방향\n",
        "concat_2 = np.concatenate((arr1, arr2), axis=1)  # column 방향\n",
        "\n",
        "print(concat_1)\n",
        "print(concat_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaYKXV27ge4E"
      },
      "source": [
        "## Q3. 3번부터 5번까지의 미션는 Numpy를 이용해서 정답값을 예측해보는 linear regression을 구현해 보는 미션입니다. 첫번째 단계로 데이터를 준비해보도록 하겠습니다. 아래와 같이 데이터가 주어져있을 때, 경사하강법을 위한 데이터를 분리해보세요.\n",
        "\n",
        "- 주어진 xy 데이터를 이용해서 학습과 정답 데이터를 준비해보세요.\n",
        "- *추가 수정* 문제에서 주어진 xy에서 대괄호를 한 번 더 묶어주어야 문제 해결이 가능합니다.\n",
        "(차원 관련)  (np.array([[1., 2., 3., 4., 5., 6.], [10., 20., 30., 40., 50., 60.]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3brpP0--gliN",
        "outputId": "9b7f41bd-c613-45d7-e501-39a5c8003c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 2. 3. 4. 5. 6.] (6,)\n",
            "[10. 20. 30. 40. 50. 60.] (6,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "               [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "x_train = xy[0]\n",
        "y_train = xy[1]\n",
        "\n",
        "print(x_train, x_train.shape)\n",
        "print(y_train, y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qapF40D2hSrZ"
      },
      "source": [
        "## Q4. 경사 하강법 구현을 위해서 위에서 분리한 x_train 데이터와 계산될 weight, bias 값을 정의해보세요. 여기서 구현한 weight와 bias 는 linear regression 계산을 진행할시 직선의 기울기와 y 절편의 값이 됩니다.\n",
        "\n",
        "- numpy 내의 random 함수를 이용해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYMLaanShZNf",
        "outputId": "5f7be7e6-a728-4f1b-9784-f79799f75377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.60635678] [0.41199666]\n"
          ]
        }
      ],
      "source": [
        "beta_gd = np.random.rand(1)\n",
        "bias = np.random.rand(1)\n",
        "\n",
        "print(beta_gd, bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43THkmERiEPV"
      },
      "source": [
        "## Q5. 이제 최종적으로 linear regression을 경사하강법으로 학습하는 코드를 구현해봅시다. 경사하강법 구현을 위한 학습 Loop를 구현해보세요. 최종적으로 1000회 반복했을 시에 결과를 출력하세요.\n",
        "\n",
        "- 단, Error는 차이의 제곱을 이용해서 계산해주세요.\n",
        "- Gradient 값은 우리가 예측하는 각 변수에 대한 미분값입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rakJGXOsiJEv",
        "outputId": "577a2469-8de4-4ab9-b2ec-e1c0185d8a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch (       100/1000) error:   0.848005, beta_gd:   9.511446, bias:   2.091596\n",
            "Epoch (       200/1000) error:   0.408162, beta_gd:   9.661055, bias:   1.451092\n",
            "Epoch (       300/1000) error:   0.196457, beta_gd:   9.764849, bias:   1.006727\n",
            "Epoch (       400/1000) error:   0.094558, beta_gd:   9.836859, bias:   0.698440\n",
            "Epoch (       500/1000) error:   0.045513, beta_gd:   9.886817, bias:   0.484558\n",
            "Epoch (       600/1000) error:   0.021906, beta_gd:   9.921477, bias:   0.336173\n",
            "Epoch (       700/1000) error:   0.010544, beta_gd:   9.945523, bias:   0.233228\n",
            "Epoch (       800/1000) error:   0.005075, beta_gd:   9.962205, bias:   0.161807\n",
            "Epoch (       900/1000) error:   0.002443, beta_gd:   9.973779, bias:   0.112257\n",
            "Epoch (      1000/1000) error:   0.001176, beta_gd:   9.981809, bias:   0.077881\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
        "               [10., 20., 30., 40., 50., 60.]])\n",
        "\n",
        "x_train = xy[0]\n",
        "y_train = xy[1]\n",
        "\n",
        "beta_gd = np.random.rand(1)\n",
        "bias = np.random.rand(1)\n",
        "\n",
        "learning_rate = 0.01\n",
        "EPOCH = 1000\n",
        "\n",
        "for i in range(EPOCH):\n",
        "\n",
        "  y_hat = (x_train * beta_gd) + bias\n",
        "  error = ((y_hat - y_train) ** 2).mean()\n",
        "\n",
        "  gd_w = ((y_hat - y_train) * 2 * x_train).mean()\n",
        "  gd_b = ((y_hat - y_train) * 2).mean()\n",
        "\n",
        "  beta_gd -= learning_rate * gd_w\n",
        "  bias -= learning_rate * gd_b\n",
        "\n",
        "  if (i+1) % 100 == 0:\n",
        "    print(f\"Epoch ({i+1:10d}/{EPOCH}) error: {error:10f}, beta_gd: {beta_gd.item():10f}, bias: {bias.item():10f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 참고\n",
        "- https://velog.io/@amobmocmo/Python-단순-선형-회귀-Linear-Regression-구현-9ik2uej68q"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
